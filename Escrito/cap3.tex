\chapter{BASE TEÓRICA}

En este capítulo se presentará una introducción teórica de la herramienta de neuroevolución HyperNEAT y sus componentes, necesaria para la implementación de \(\tau\)-HyperNEAT.

\section{COMPOSITIONAL PATTERN PRODUCING NETWORKS}

La representación es uno de los elementos principales en la IA. Particularmente cuando un problema involucra búsquedas, una buena representación del espacio de solución puede hacer la diferencia entre éxito y fracaso. En computación evolutiva, como los genomas tradicionales de tamaño fijo y codificaciones directas alcanzan sus límites, la importancia de la representación se ha movido al frente de la investigación. %Mientras tanto, la biología sigue siendo una constante motivación que nos recuerda que tan lejos es posible llegar. 

En biología, los genes en el ADN representan estructuras tremendamente complejas con miles de millones de partes interconectadas, tal como lo es el cerebro humano. Sin embargo el ADN no contiene miles de millones de genes, de echo, solo treinta mil genes codifican todo el cuerpo. Esta es la razón para creer que el descubrimiento de sistemas tan complejos como el de los seres humanos es solo posible a través de una extraordinariamente eficiente codificación, como se ve en la naturaleza. Un proceso clave en la codificación en la naturaleza es la reutilización de genes ya que el mismo gen puede ser activado en cualquier lugar y en cualquier momento en el proceso de desarrollo. Así un pequeño conjunto de genes puede codificar un conjunto mucho mas grande de componentes estructurales.

Esta observación ha inspirado un campo activo de investigación en la \textsl{codificacion de desarrollo} artificial. El objetivo es encontrar la correcta abstracción del desarrollo natural, por un computador corriendo un algoritmo evolutivo, de modo que pueda comenzar a descubrir la complejidad en una escala natural. Una faceta común de algunas abstracciones es que un estado de un componente individual del fenotipo en un momento del desarrollo afecta los estados de los componentes de la misma vecindad en el futuro, es decir, el desarrollo se despliega a través de interacciones locales. Debido a que ninguna abstracción se ha acercado hasta ahora a descubrir el nivel de complejidad visto en la naturaleza, sigue siendo de gran interés identificar las propiedades de abstracción que dan lugar a una codificación eficiente.

El principal aporte detrás de ``Compositional Pattern Producing Networks'' (CPPNs), es que es posible describir directamente las relaciones estructurales que resultan de un proceso de desarrollo sin simular el proceso mismo. En su lugar, la descripción es codificada a través de una composición de funciones, cada una de estas basadas en el patrón de gradientes observado en embriones en la naturaleza.

Desde una perspectiva estructura CPPNs y ANNs son muy similares debido a que métodos designados para evolucionar ANNs también pueden evolucionar CPPNs. En particular, el método de ``NeuroEvolution of Augmenting Topologies'' (NEAT) es una buena opción para evolucionar CPPNs porque NEAT incrementa la complejidad de las redes a medida que evolucionan generación tras generación, permitiendo que se generen cada vez regularidades mas elaboradas.

En el siguiente sección se introducirán importantes características de patrones de desarrollo.

\subsection{PATRONES DE DESARROLLO}

El desarrollo produce patrones y la evolución produce secuencias de patrones generación tras generación. Los patrones incluyen regularidades y las regularidades son las que hacen posible una reutilización en la codificación. Sin regularidad, la misma información no puede producir distintas partes de un mismo fenotipo, reduciendo mucho las ventajas del desarrollo. A continuación se mencionaran características generales de patrones observados en organismos de la naturaleza que también puede buscarse en fenotipos evolucionado artificialmente.

\begin{itemize}
\item[\textbf{Repetición }] Múltiples instancias de la misma subestructura es un sello distintivo de los organismos biológicos. Desde las células de todo el cuerpo hasta las neuronas del cerebro, las mismas estructuras se repiten una y otra vez en un único organismo. La repetición en el fenotipo también se llama auto similitud.
\item[\textbf{Repetición con variaciones }] Frecuentemente estructuras se encuentran repetidas pero no de forma completamente idénticas. Esto se ve de forma frecuente en toda la naturaleza, como por ejemplo en las vertebras de una columna o en los mismos dedos de una mano, cada una de sus componentes posee la misma estructura pero con distintas variaciones.
\item[\textbf{Simetría }] A menudo las repeticiones ocurren a través de las simetrías, como cuando los lados derecho e izquierdo del cuerpo son idénticas, produciéndose una simetría bilateral.
\item[\textbf{Simetría imperfecta }] Mientras que un tema simétrico general es observable en muchas estructuras biológicas, muchas veces no son perfectamente simétricas. Tal simetría imperfecta es una característica común de repetición con variaciones. El cuerpo humano es simétrico en general, pero no es equitativo en ambos lados; algunos órganos solo aparecen en uno de los lados, y un lado es generalmente dominante sobre el otro.
\item[\textbf{Regularidades elaboradas }] Durante muchas generaciones, regularidades son a menudo elaboradas y mucho mas explotadas, como por ejemplo las aletas de los peces con simetría bilateral temprana que con el tiempo se convirtieron en los brazos y manos de mamíferos.
\item[\textbf{Preservación de regularidades }] Durante generaciones, determinadas regularidades son estrictamente preservadas. Simetrías bilaterales no producen fácilmente simetrías de tres vías, y animales cuadrúpedos raramente producen crías con distinto numero de extremidades.
\end{itemize}

Usando esta lista, fenotipos y linajes producidos por codificaciones artificiales pueden ser analizados en base a características presentes naturalmente, dando una indicación de si una codificación particular esta capturando propiedades y capacidades esenciales de un desarrollo natural.

La siguiente sección describe un proceso mediante el cual los patrones representados por un conjunto de genes pueden llegar a ser cada vez más complejos.

\subsection{COMPLEJIFICACIÓN}

EL proceso de complejificación permite a la evolución descubrir fenotipos más complejos de los que sería posible descubrir a través de la optimización de un conjunto fijo de genes. 

En la búsqueda de la solución a un problema particular, cuya dimensión es desconocido a priori, mientras más dimensiones tenga el espacio de solución seleccionado, más difícil se hace descubrir esta solución. En otras palabras, soluciones mas complejas son mas difíciles de evolucionar que otras mas simples. Codificaciones de desarrollo intentan reducir la complejidad del espacio de búsqueda mediante la codificación de un fenotipo complejo en un genotipo de dimensiones significativamente menores.

Sin embargo esta reducción no elimina el problema de dimensionalidad, ya que aun se necesitan de miles de genes para representar fenotipos con altos grados de complejidad, y a pesar de que la compresión entre el genotipo y el fenotipo es realmente substancial, el espacio de búsqueda del genotipo aun sigue siendo prohibitivamente complejo para su búsqueda directa.

La razón de por qué la evolución puede superar el problema de la complejidad es que no se inicia la búsqueda en un espacio de la misma complejidad que la solución final. Nuevos genes son ocasionalmente añadidos al genoma, permitiendo a la evolución complejizar funciones por sobre el proceso de optimización. La complejificación permite a la evolución comenzar con fenotipos simples partiendo por un espacio de busqueda dimensionalmente más pequeño para trabajar sobre este de manera incremental, opuesto a la idea de trabajar directamente a partir de sistemas más elaborados desde el comienzo.

Este proceso de añadir nuevos genes de manera gradual es confirmado por la evolución en la naturaleza y ha demostrado una mejora en la adaptación. Nuevos genes comúnmente aparecen a través de duplicación de otros genes, que es un tipo espacial de mutación en donde uno o más genes de los padres son copiados en un genoma hijo más de una vez. La duplicación de genes ha sido responsable de las innovaciones clave en la morfología general del cuerpo a lo largo de la evolución natural. El principal efecto de la duplicación de genes es el incremento de la dimensionalidad del genotipo, con lo que se podrán representar patrones fenotípicos cada vez más complejos. Por lo tanto, complejización y la codificación de desarrollo trabajan conjuntos para producir fenotipos complejos.

















 La siguiente sección describe el método  NEAT.

%HyperNEAT utiliza una codificación llamada ``Compositional Pattern Producing Networks'' (connective CPPNs), el cual puede representar patrones de conectividad como función del espacio cartesiano. Específicamente, connective CPPNs representa patrones dentro de un hiperespacio que es mapeado a un patron de conectividad dimensionalmente mas pequeño. De esta manera connective CPPNs evolucionado con HyperNEAT puede codificar redes neuronales artificiales de gran escala para descubrir regularidades a lo largo sus dimensiones geométricas motivado por la evolución de cerebros biológicos en la naturaleza.
%


\section{NEUROEVOLUTION OF AUGMENTING TOPOLOGIES}

``NeuroEvolution of Augmenting Topologies'' (NEAT) \cite{neat} usa algoritmos genéticos para hacer evolucionar la topología y los pesos entre conexiones de una red neuronal de acuerdo a una función de desempeño. Debido al fundamento que tienen los algoritmos genéticos, NEAT hace evolucionar la red neuronal en base al individuo más fuerte (de mejor desempeño), teniendo una gran probabilidad de crear una nueva generación de individuos o redes neuronales, y así preservar la especie.

Una de las principales ventajas de NEAT, comparada con otros tipos de redes neuronales, es que la estructura inicial de la red (topología) no es necesaria, pero es encontrada a través del proceso de neuroevolución del algoritmo mismo. Cada red NEAT es codificada por un genoma, como se muestra en la Figura \ref{genoma}, en donde la red es representada por Genes de Nodo y Genes de Conexión, representando a neuronas y conexiones respectivamente. Cada Nodo o Conexión tiene un único numero Id de innovación, el cual se preserva si el Nodo o Conexión es removido (como resultado de la evolución) o creado nuevamente.

\begin{figure}[H]
\centering
\includegraphics[scale=1]{fig/usmLogo.png}
\caption{Ejemplo de Genoma usado en NEAT para codificar la red neuronal mostrada a su derecha.}
\label{genoma}
\end{figure}

La evolución del genoma que forma la red NEAT es impulsado por su desempeño dada una función de desempeño determinada. La función de desempeño determina la probabilidad de reproducción de un genoma en específico. Los hijos generados por el mecanismo de reproducción conservará los nodos y conexiones del padre y aleatoriamente cambiará los pesos de sus conexiones. Si una conexión solo proviene de uno de los padres, esta es heredada instantáneamente. Una especie es obtenida cuando un grupo de redes neuronales comparten similitudes entre ellas, esto es cuando, la distancia entre ellos está bajo un umbral (el cual depende de la topología de la red y los pesos de las conexiones). Redes neuronales pertenecientes a una misma especie tienen una alta probabilidad de convertirse en padres de una nueva población de redes neuronales. Similarmente a los algoritmos genéticos, la variabilidad en el proceso de reproducción en redes NEAT es dado por mutaciones. Aquí las mutaciones permiten la creación de nuevos nodos y la modificación de conexiones entre nodos (crear, eliminar o modular los pesos entre conexiones).

\section{HYPERNEAT}

Una extensión de NEAT, es el algoritmo de codificación generativa Hypercubo basado en Neuroevolución a través del Aumento de Topologías (HyperNEAT) \cite{hyperneat}. HyperNEAT es formado por dos redes neuronales: la red principal llamada substrato, y una segunda red neuronal NEAT usada para generar los pesos de las conexiones en el substrato. La topología del substrato es fija (no evoluciona), y está relacionada con la existencia de restricciones espaciales. El substrato está conformado por un número fijo de neuronas y capas: una capa de entrada, una capa de salida y capas intermedias; donde cada neurona de la red tiene una posición espacial asignada.

Las conexiones entre neuronas del substrato son obtenidas a través de la segunda red neuronal implementada por NEAT. La red NEAT recibe como entrada la posición espacial de los nodos que van a ser conectados, representadas como coordenadas de una matriz abstracta (véase la Figura \ref{hyperneat}). La salida de la red NEAT corresponde al peso entre la conexión entre esas dos neuronas. Siguiendo esta implementación, HyperNEAT toma ventaja de las simetrías y regularidades en la geometría del substrato para resolver el problema planteado con sus restricciones espaciales.

Información adicional puede ser usada como entrada de la red para realzar las características geométricas de la red implementada, como por ejemplo la distancia euclidiana entre neuronas.

\begin{figure}[H]
\centering
\includegraphics[scale=1]{fig/usmLogo.png}
\caption{Algoritmo HyperNEAT formado por dos redes neuronales distintas. La red principal `Substrato' conforma la red con información estructural y puede ser formada por muchas capas. Las conexiones de pesos entre neuronas en el Substrato son obtenidas usando la red neuronal secundaria implementada por NEAT.}
\label{hyperneat}
\end{figure}

El beneficio de un cierto set de conexiones en la implementación de HyperNEAT es evaluada por una función de desempeño. El resultado del desempeño es posteriormente pasado a la red secundaria NEAT con el fin de evolucionar los pesos de las conexiones entre nodos. Se elige entonces el conjunto de pesos de conexiones dado el mejor valor de desempeño obtenido como una solución del problema de optimización.

